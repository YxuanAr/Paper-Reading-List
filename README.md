# Paper-Reading-List
This is a paper reading list for myself. I am focusing on the multimodal alignment and also interest in other area.

## Vision Language Basic Model 
- \[2024.6.11\] \[Auto-regressive\] \[<font color=red>arxiv</font>\] [Generative Multimodal Models are In-Context Learners (EMU2).](https://arxiv.org/pdf/2312.13286) (BAAI,THU,PKU)
- \[2024.6.11\] \[ICL\] \[<font color=red>arxiv</font>\] [What Makes Multimodal In-Context Learning Work?](https://arxiv.org/pdf/2404.15736) (Sorbonne Universite)
- \[2024.6.11\] \[ICL\] \[<font color=red>ICLR2024</font>\] [Beyond Task Performance: Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning.](https://arxiv.org/pdf/2310.00647) (Sorbonne Universite)
- \[2024.6.11\] \[Understanding\] \[<font color=red>arxiv</font>\] [On the Out-Of-Distribution Generalization of Multimodal Large Language Models.](https://arxiv.org/pdf/2402.06599) (THU)
- \[2024.6.11\] \[ICL\] \[<font color=red>arxiv</font>\] [Understanding and Improving In-Context Learning on Vision-language Models.](https://arxiv.org/pdf/2311.18021) (LMU,Oxford)

## Outdoor Scene and Autonomous Driving
- \[Completion\] \[CVPR2024*\] \[2024.6.13\] [PaSCo: Urban 3D Panoptic Scene Completion with Uncertainty Awareness](https://arxiv.org/pdf/2312.02158) (TUM)
